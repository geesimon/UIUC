---
title: "Simulation Project"
author: "STAT 420, Summer 2017, Xiaoming Ji"
date: ''
output:
  html_document: 
    toc: yes
  pdf_document: default
---

## Simulation Study 1, Estimate Distributions

### Introduction
In this simulation study we will investigate the distribution of regression estimates $\hat{\beta}_1$, $s_e^2$ and $\hat{\text{E}}[Y]$ from MLR model

$$
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3}  + \beta_4 x_{i4} + \epsilon_i
$$
We will discuss how these estimates relate to true distributions and the impact of different $\sigma$.


### Methods

#### Setup
For this MLR model, we assign

- $\beta_0 = 2$
- $\beta_1 = 1$
- $\beta_2 = 1$
- $\beta_3 = 1$
- $\beta_4 = 1$
- $\epsilon_i \sim N(0, \sigma^2)$ 

We will use the sample data found in [`study_1.csv`](study_1.csv) with size of 15 to train this model, three possible levels of noise and test values for $x_{i}$. 

- n = 15
- $\sigma \in (1, 5, 10)$
- $\hat{\text{E}}[Y \mid x_1 = -3, x_2 = 2.5, x_3 = 0.5, x_4 = 0]$

To start, we initialize the seed, set constants, load data and allocate memory for the estimates

```{r, message=FALSE}
library(readr)

birthday = 19720816
set.seed(birthday)

beta_0 = 2
beta_1 = 1
beta_2 = 1
beta_3 = 1
beta_4 = 1
sigma = c(1, 5, 10)
x1_test = -3
x2_test = 2.5
x3_test = 0.5
x4_test = 0


num_sims = 300

sim_data = read_csv("study_1.csv")
sample_size = nrow(sim_data)

beta_hat_1 = matrix(data = c(0), nrow = num_sims, ncol = length(sigma))
se_square = matrix(data = c(0), nrow = num_sims, ncol = length(sigma))
y_hat = matrix(data = c(0), nrow = num_sims, ncol = length(sigma))
```

#### Simulation
We now perform the simulation `r num_sims` of times for each $\sigma$. Each time, we update the y variable in the data frame, leaving the x variables the same. We then fit a model, and store $\hat{\beta}_1$, $s_e^2$ and compute $\hat{\text{E}}[Y]$.

```{r}
for (s in 1:length(sigma)) {
  for (i in 1:num_sims) {
    eps           = rnorm(sample_size, mean = 0 , sd = sigma[s])
    sim_data$y    = beta_0 + beta_1 * sim_data$x1 + beta_2 * sim_data$x2 + beta_3 * sim_data$x3 +
                    beta_4 * sim_data$x4 + eps
    fit           = lm(y ~ ., data = sim_data)
    
    beta_hat_1[i, s]  = coef(fit)[2]
    se_square[i, s]   = sum(fit$residuals ^ 2) / (sample_size - ncol(sim_data))
    y_hat[i, s]       = predict(fit, newdata = data.frame(x1 = x1_test, x2 = x2_test, x3 = x3_test, x4 = x4_test ))
  }
}

```


### Results
### Discussion

For this exercise we will use the data stored in [`nutrition.csv`](nutrition.csv). It contains the nutritional values per serving size for a large variety of foods as calculated by the USDA. It is a cleaned version totaling 5,138 observations and is current as of September 2015.

The variables in the dataset are:

- `ID` 
- `Desc` - Short description of food
- `Water` - in grams
- `Calories` 
- `Protein` - in grams
- `Fat` - in grams
- `Carbs` - Carbohydrates, in grams
- `Fiber` - in grams
- `Sugar` - in grams
- `Calcium` - in milligrams
- `Potassium` - in milligrams
- `Sodium` - in milligrams
- `VitaminC` - Vitamin C, in milligrams
- `Chol` - Cholesterol, in milligrams
- `Portion` - Description of standard serving size used in analysis

**(a)** Fit the following multiple linear regression model in `R`. Use `Calories` as the response and `Carbs`, `Fat`, and `Protein` as predictors.

\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \epsilon_i.
\]

Here,

- $Y_i$ is `Calories`.
- $x_{i1}$ is `Carbs`.
- $x_{i2}$ is `Fat`.
- $x_{i3}$ is `Protein`.

Use an $F$-test to test the significance of the regression. Report the following:
 
- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.


- $H_0: \beta_1 = \beta_2 = \beta_{3} = 0$
- $H_1: \text{At least one of } \beta_j \neq 0, j = 1, 2, 3$

Note that we used the [`broom` package](https://cran.r-project.org/web/packages/broom/vignettes/broom.html) to obtain some results directly. This is a useful package for "cleaning" some of the default `R` output.

**(b)** Output only the estimated regression coefficients. Interpret all $\hat{\beta}_j$ coefficients in the context of the problem.

**(c)** Use your model to predict the number of `Calories` in a Big Mac. According to [McDonald's publicized nutrition facts](http://nutrition.mcdonalds.com/getnutrition/nutritionfacts.pdf), the Big Mac contains 47g of carbohydrates, 28g of fat, and 25g of protein.


**(d)** Calculate the standard deviation, $s_y$, for the observed values in the Calories variable. Report the value of $s_e$ from your multiple regression model. Interpret both estimates in the context of this problem.


## Simulation Study 2, RMSE for Selection?
### Introduction
### Methods
### Results
### Discussion

For this exercise we will use the data stored in [`goalies_cleaned.csv`](goalies_cleaned.csv). It contains career data for 462 players in the National Hockey League who played goaltender at some point up to and including the 2014-2015 season. The variables in the dataset are:
 
- `W` - Wins
- `GA` - Goals Against
- `SA` - Shots Against
- `SV` - Saves
- `SV_PCT` - Save Percentage
- `GAA` - Goals Against Average
- `SO` - Shutouts
- `MIN` - Minutes
- `PIM` - Penalties in Minutes

For this exercise we will consider three models, each with Wins as the response. The predictors for these models are:

- Model 1: Goals Against, Shots Against, Saves
- Model 2: Goals Against, Shots Against, Saves, Minutes, Penalties in Minutes
- Model 3: All Available


**(a)** Use an $F$-test to compares models 1 and 2. Report the following:

- The null hypothesis
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$
- The model you prefer


**(b)** Use an $F$-test to compare model 3 to your preferred model from part **(a)**. Report the following:

- The null hypothesis
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$
- The model you prefer


**(c)** Use a $t$-test to test $H_0: \beta_{\text{SA}} = 0 \ \text{vs} \ H_1: \beta_{\text{SA}} \neq 0$ for the model you preferred in part **(b)**. Report the following:

- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$


## Simulation Study 3, Power
### Introduction
### Methods
### Results
### Discussion

For this exercise we will once again use the data stored in [`goalies_cleaned.csv`](goalies_cleaned.csv). The goal of this exercise is to fit a model with `W` as the response and the remaining variables as predictors.

**(a)** Obtain the estimated regression coefficients **without** the use of `lm()` or any other built-in functions for regression. That is, you should use only matrix operations. Store the results in a vector `beta_hat_no_lm`. To ensure this is a vector, you may need to use `as.vector()`. Return this vector as well as the results of `sum(beta_hat_no_lm)`.



**(b)** Obtain the estimated regression coefficients **with** the use of `lm()`. Store the results in a vector `beta_hat_lm`. To ensure this is a vector, you may need to use `as.vector()`. Return this vector as well as the results of `sum(beta_hat_lm)`.

Notice the sum is the same, but we will complete one more step to verify equality.

**(c)** Use the `all.equal()` function to verify that the results are the same. You may need to remove the names of one of the vectors. The `as.vector()` function will do this as a side effect, or you can directly use `unname()`.

**Solution:**


Note that `all.equal()` allows for some minor differences. It only looks for "near equality." If we investigate further, we'd notice that in reality none of the estimates are the same.


But why is this? While we do know the analytic solution


it is not what `R` is using when calculating the regression coefficients using `lm()`. In reality, `R` is using a [QR decomposition](https://en.wikipedia.org/wiki/QR_decomposition) for speed and stability of the needed matrix operations. This creates very small numerical differences in the results.

**(d)** Calculate $s_e$ without the use of `lm()`. That is, continue with your results from **(a)** and perform additional matrix operations to obtain the result. Output this result. Also, verify that this result is the same as the result obtained from `lm()`.


**(e)** Calculate $R^2$ without the use of `lm()`. That is, continue with your results from **(a)** and **(d)**, and perform additional operations to obtain the result. Output this result. Also, verify that this result is the same as the result obtained from `lm()`.

